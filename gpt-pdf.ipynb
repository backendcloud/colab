{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/backendcloud/colab/blob/main/gpt-pdf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TOKEN = \"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\""
      ],
      "metadata": {
        "id": "fKVntsLVrHtN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "foDRvphmoPJi"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "res = requests.get('https://cdn.openai.com/papers/gpt-4.pdf')\n",
        "with open('gpt-4.pdf', 'wb') as f:\n",
        "  f.write(res.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pypdf\n"
      ],
      "metadata": {
        "id": "FfH8SYknpJGu",
        "outputId": "64778ed3-07a5-46ab-80f4-52072c771530",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-3.7.0-py3-none-any.whl (246 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.9/246.9 KB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=3.10.0.0 in /usr/local/lib/python3.9/dist-packages (from pypdf) (4.5.0)\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-3.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pypdf import PdfReader\n",
        "\n",
        "reader = PdfReader(\"gpt-4.pdf\")\n",
        "number_of_pages = len(reader.pages)\n",
        "page = reader.pages[0]\n",
        "text = page.extract_text()"
      ],
      "metadata": {
        "id": "G9Aa8DKapM3P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "id": "-Y7eNQiapOCO",
        "outputId": "49d13e3a-e9cd-4200-e42d-a3acf9ce0509",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GPT-4 Technical Report\\nOpenAI\\x03\\nAbstract\\nWe report the development of GPT-4, a large-scale, multimodal model which can\\naccept image and text inputs and produce text outputs. While less capable than\\nhumans in many real-world scenarios, GPT-4 exhibits human-level performance\\non various professional and academic benchmarks, including passing a simulated\\nbar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-\\nbased model pre-trained to predict the next token in a document. The post-training\\nalignment process results in improved performance on measures of factuality and\\nadherence to desired behavior. A core component of this project was developing\\ninfrastructure and optimization methods that behave predictably across a wide\\nrange of scales. This allowed us to accurately predict some aspects of GPT-4’s\\nperformance based on models trained with no more than 1/1,000th the compute of\\nGPT-4.\\n1 Introduction\\nThis technical report presents GPT-4, a large multimodal model capable of processing image and\\ntext inputs and producing text outputs. Such models are an important area of study as they have the\\npotential to be used in a wide range of applications, such as dialogue systems, text summarization,\\nand machine translation. As such, they have been the subject of substantial interest and progress in\\nrecent years [1–34].\\nOne of the main goals of developing such models is to improve their ability to understand and generate\\nnatural language text, particularly in more complex and nuanced scenarios. To test its capabilities\\nin such scenarios, GPT-4 was evaluated on a variety of exams originally designed for humans. In\\nthese evaluations it performs quite well and often outscores the vast majority of human test takers.\\nFor example, on a simulated bar exam, GPT-4 achieves a score that falls in the top 10% of test takers.\\nThis contrasts with GPT-3.5, which scores in the bottom 10%.\\nOn a suite of traditional NLP benchmarks, GPT-4 outperforms both previous large language models\\nand most state-of-the-art systems (which often have benchmark-speciﬁc training or hand-engineering).\\nOn the MMLU benchmark [ 35,36], an English-language suite of multiple-choice questions covering\\n57 subjects, GPT-4 not only outperforms existing models by a considerable margin in English, but\\nalso demonstrates strong performance in other languages. On translated variants of MMLU, GPT-4\\nsurpasses the English-language state-of-the-art in 24 of 26 languages considered. We discuss these\\nmodel capability results, as well as model safety improvements and results, in more detail in later\\nsections.\\nThis report also discusses a key challenge of the project, developing deep learning infrastructure and\\noptimization methods that behave predictably across a wide range of scales. This allowed us to make\\npredictions about the expected performance of GPT-4 (based on small runs trained in similar ways)\\nthat were tested against the ﬁnal run to increase conﬁdence in our training.\\nDespite its capabilities, GPT-4 has similar limitations to earlier GPT models [ 1,37,38]: it is not fully\\nreliable (e.g. can suffer from “hallucinations”), has a limited context window, and does not learn\\n\\x03Please cite this work as “OpenAI (2023)\". Full authorship contribution statements appear at the end of the\\ndocument. Correspondence regarding this technical report can be sent to gpt4-report@openai.comarXiv:submit/4812508  [cs.CL]  27 Mar 2023'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install nltk"
      ],
      "metadata": {
        "id": "_QMACjmBpXbH",
        "outputId": "0bb70b9d-7c19-4977-ccab-5fb5f2db01c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "id": "Ity9gJwDpgl3",
        "outputId": "83acc8fe-00b3-4293-a8d2-1e84f9088902",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = sent_tokenize(text)"
      ],
      "metadata": {
        "id": "YERFHeSTqRsG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in sentences:\n",
        "    print(sentence)\n",
        "    print('=' * 20)"
      ],
      "metadata": {
        "id": "9m6JqC4rqmnJ",
        "outputId": "c87872e8-1ab8-4165-ccae-d7ab519c2626",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT-4 Technical Report\n",
            "OpenAI\u0003\n",
            "Abstract\n",
            "We report the development of GPT-4, a large-scale, multimodal model which can\n",
            "accept image and text inputs and produce text outputs.\n",
            "====================\n",
            "While less capable than\n",
            "humans in many real-world scenarios, GPT-4 exhibits human-level performance\n",
            "on various professional and academic benchmarks, including passing a simulated\n",
            "bar exam with a score around the top 10% of test takers.\n",
            "====================\n",
            "GPT-4 is a Transformer-\n",
            "based model pre-trained to predict the next token in a document.\n",
            "====================\n",
            "The post-training\n",
            "alignment process results in improved performance on measures of factuality and\n",
            "adherence to desired behavior.\n",
            "====================\n",
            "A core component of this project was developing\n",
            "infrastructure and optimization methods that behave predictably across a wide\n",
            "range of scales.\n",
            "====================\n",
            "This allowed us to accurately predict some aspects of GPT-4’s\n",
            "performance based on models trained with no more than 1/1,000th the compute of\n",
            "GPT-4.\n",
            "====================\n",
            "1 Introduction\n",
            "This technical report presents GPT-4, a large multimodal model capable of processing image and\n",
            "text inputs and producing text outputs.\n",
            "====================\n",
            "Such models are an important area of study as they have the\n",
            "potential to be used in a wide range of applications, such as dialogue systems, text summarization,\n",
            "and machine translation.\n",
            "====================\n",
            "As such, they have been the subject of substantial interest and progress in\n",
            "recent years [1–34].\n",
            "====================\n",
            "One of the main goals of developing such models is to improve their ability to understand and generate\n",
            "natural language text, particularly in more complex and nuanced scenarios.\n",
            "====================\n",
            "To test its capabilities\n",
            "in such scenarios, GPT-4 was evaluated on a variety of exams originally designed for humans.\n",
            "====================\n",
            "In\n",
            "these evaluations it performs quite well and often outscores the vast majority of human test takers.\n",
            "====================\n",
            "For example, on a simulated bar exam, GPT-4 achieves a score that falls in the top 10% of test takers.\n",
            "====================\n",
            "This contrasts with GPT-3.5, which scores in the bottom 10%.\n",
            "====================\n",
            "On a suite of traditional NLP benchmarks, GPT-4 outperforms both previous large language models\n",
            "and most state-of-the-art systems (which often have benchmark-speciﬁc training or hand-engineering).\n",
            "====================\n",
            "On the MMLU benchmark [ 35,36], an English-language suite of multiple-choice questions covering\n",
            "57 subjects, GPT-4 not only outperforms existing models by a considerable margin in English, but\n",
            "also demonstrates strong performance in other languages.\n",
            "====================\n",
            "On translated variants of MMLU, GPT-4\n",
            "surpasses the English-language state-of-the-art in 24 of 26 languages considered.\n",
            "====================\n",
            "We discuss these\n",
            "model capability results, as well as model safety improvements and results, in more detail in later\n",
            "sections.\n",
            "====================\n",
            "This report also discusses a key challenge of the project, developing deep learning infrastructure and\n",
            "optimization methods that behave predictably across a wide range of scales.\n",
            "====================\n",
            "This allowed us to make\n",
            "predictions about the expected performance of GPT-4 (based on small runs trained in similar ways)\n",
            "that were tested against the ﬁnal run to increase conﬁdence in our training.\n",
            "====================\n",
            "Despite its capabilities, GPT-4 has similar limitations to earlier GPT models [ 1,37,38]: it is not fully\n",
            "reliable (e.g.\n",
            "====================\n",
            "can suffer from “hallucinations”), has a limited context window, and does not learn\n",
            "\u0003Please cite this work as “OpenAI (2023)\".\n",
            "====================\n",
            "Full authorship contribution statements appear at the end of the\n",
            "document.\n",
            "====================\n",
            "Correspondence regarding this technical report can be sent to gpt4-report@openai.comarXiv:submit/4812508  [cs.CL]  27 Mar 2023\n",
            "====================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install openai"
      ],
      "metadata": {
        "id": "X0_UWD1Oqsi-",
        "outputId": "e42310a5-0019-49c9-e16c-a7c3a437e687",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.1/70.1 KB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.2 yarl-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai.api_key = TOKEN\n",
        "\n",
        "completion = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": \"请你成为文章翻译的小帮手，请协助翻译以下技术文件，以简体中文输出\"},\n",
        "        {\"role\": \"user\", \"content\": sentences[0]},\n",
        "    ]\n",
        ")\n",
        "completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "Rx30izBtqysm",
        "outputId": "94f7120f-2bd6-4ee7-f61b-baa72447b0c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GPT-4技术报告\\nOpenAI\\n摘要\\n本文报告了GPT-4的开发情况，这是一个大规模的、多模态模型，能够接受图像和文本输入，并生成文本输出。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentences = ''\n",
        "chunks = []\n",
        "for sentence in sentences:\n",
        "  input_sentences += sentence\n",
        "  if len(input_sentences) > 1000:\n",
        "    chunks.append(input_sentences)\n",
        "    input_sentences = ''\n",
        "chunks.append(input_sentences)\n",
        "chunks"
      ],
      "metadata": {
        "id": "DbSKPHKNq_6-",
        "outputId": "3f8bf251-75d6-4028-b400-5eca23e0c8c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['GPT-4 Technical Report\\nOpenAI\\x03\\nAbstract\\nWe report the development of GPT-4, a large-scale, multimodal model which can\\naccept image and text inputs and produce text outputs.While less capable than\\nhumans in many real-world scenarios, GPT-4 exhibits human-level performance\\non various professional and academic benchmarks, including passing a simulated\\nbar exam with a score around the top 10% of test takers.GPT-4 is a Transformer-\\nbased model pre-trained to predict the next token in a document.The post-training\\nalignment process results in improved performance on measures of factuality and\\nadherence to desired behavior.A core component of this project was developing\\ninfrastructure and optimization methods that behave predictably across a wide\\nrange of scales.This allowed us to accurately predict some aspects of GPT-4’s\\nperformance based on models trained with no more than 1/1,000th the compute of\\nGPT-4.1 Introduction\\nThis technical report presents GPT-4, a large multimodal model capable of processing image and\\ntext inputs and producing text outputs.',\n",
              " 'Such models are an important area of study as they have the\\npotential to be used in a wide range of applications, such as dialogue systems, text summarization,\\nand machine translation.As such, they have been the subject of substantial interest and progress in\\nrecent years [1–34].One of the main goals of developing such models is to improve their ability to understand and generate\\nnatural language text, particularly in more complex and nuanced scenarios.To test its capabilities\\nin such scenarios, GPT-4 was evaluated on a variety of exams originally designed for humans.In\\nthese evaluations it performs quite well and often outscores the vast majority of human test takers.For example, on a simulated bar exam, GPT-4 achieves a score that falls in the top 10% of test takers.This contrasts with GPT-3.5, which scores in the bottom 10%.On a suite of traditional NLP benchmarks, GPT-4 outperforms both previous large language models\\nand most state-of-the-art systems (which often have benchmark-speciﬁc training or hand-engineering).',\n",
              " 'On the MMLU benchmark [ 35,36], an English-language suite of multiple-choice questions covering\\n57 subjects, GPT-4 not only outperforms existing models by a considerable margin in English, but\\nalso demonstrates strong performance in other languages.On translated variants of MMLU, GPT-4\\nsurpasses the English-language state-of-the-art in 24 of 26 languages considered.We discuss these\\nmodel capability results, as well as model safety improvements and results, in more detail in later\\nsections.This report also discusses a key challenge of the project, developing deep learning infrastructure and\\noptimization methods that behave predictably across a wide range of scales.This allowed us to make\\npredictions about the expected performance of GPT-4 (based on small runs trained in similar ways)\\nthat were tested against the ﬁnal run to increase conﬁdence in our training.Despite its capabilities, GPT-4 has similar limitations to earlier GPT models [ 1,37,38]: it is not fully\\nreliable (e.g.can suffer from “hallucinations”), has a limited context window, and does not learn\\n\\x03Please cite this work as “OpenAI (2023)\".',\n",
              " 'Full authorship contribution statements appear at the end of the\\ndocument.Correspondence regarding this technical report can be sent to gpt4-report@openai.comarXiv:submit/4812508  [cs.CL]  27 Mar 2023']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": \"请你成为文章翻译的小帮手，请协助翻译以下技术文件，以简体中文输出\"},\n",
        "        {\"role\": \"user\", \"content\": chunks[0]},\n",
        "    ]\n",
        ")\n",
        "completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "jjFJA_sssOw3",
        "outputId": "b6b267d6-f75c-49c3-b44a-277e6c403927",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'GPT-4技术报告\\nOpenAI\\n摘要\\n本文报道了GPT-4的开发情况，它是一个可接收图像和文本输入并生成文本输出的大规模多模态模型。虽然在许多实际情境中比人类能力差，但在各种专业和学术基准测试中，GPT-4表现出人类水平的性能，包括在模拟的律师考试中获得了约是前10%考生的成绩。GPT-4是基于Transformer的模型，预先训练以预测文档中的下一个标记。后训练对齐过程提高了其实际性能和符合所需行为的程度。该项目的核心组件是开发基础设施和优化方法，可在各种规模上可靠地预测GPT-4的某些方面性能，其中包括了通过使用不超过GPT-4计算量的1/1000的模型进行训练。\\n1介绍\\n本技术报告介绍了GPT-4，它是一个大规模多模态模型，能够处理图像和文本输入并生成文本输出。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}